[{"id":"8752c09004c1dd1e2251bd40de2925ba","title":"mm-groundingdino-趋动云","content":"在没有服务器时使用驱动云进行模型选择。\n配置环境两个一样的文档： mmdetection官方参考连接  、github文档\n趋动云镜像趋动云镜像 CUDA12.1 python&#x3D;&#x3D;3.11\n模型选择3个，bert-base-uncased、grounding_dino_swin-t_pretrain_obj365_goldg_grit9m_v3det_20231204_095047-b448804b、swin_tiny_patch4_window7_224.pth\n安装MMDetection 环境123456789101112131415# 1. 先安装torch包，后面的安装依赖torch。pip install torch==2.4.1 torchvision==0.19.1# 2. 安装mim, 然后使用min安装mmengine和mmcvpip install -U openmim # 会有一个pip 依赖Error，但不影响使用mim install mmenginemim install &quot;mmcv&gt;=2.0.0&quot;# 3. 从源码安装MMDetection# 趋动云只有内网环境，克隆不了github上的较大仓库，通过本地上传的方式# git clone https://github.com/open-mmlab/mmdetection.git# unzip mmdetection.zipcd mmdetectionpip install -v -e .# &quot;-v&quot; 指详细说明，或更多的输出# &quot;-e&quot; 表示在可编辑模式下安装项目，因此对代码所做的任何本地修改都会生效，从而无需重新安装。\n\n修改版本断言\n将/gemini/code/mmdetection/mmdet/__init__.py中对mmcv_version的断言注释掉。”mmcv&gt;&#x3D;2.0.0”安装的是2.2.0版本，但断言又要小于2.2.0，可能是一个bug吧，很久都没有修。\n验证MMDetection 环境123456# 下载配置文件和模型权重文件mim download mmdet --config rtmdet_tiny_8xb32-300e_coco --dest .python demo/image_demo.py demo/demo.jpg rtmdet_tiny_8xb32-300e_coco.py --weights rtmdet_tiny_8xb32-300e_coco_20220902_112414-78e30dcc.pth --device cpu# 你会在当前文件夹中的 outputs/vis 文件夹中看到一个新的图像 demo.jpg，图像中包含有网络预测的检测框。\n\n\n\n安装grounding_dino环境12345678# 在根目录下，cd $MMDETROOT# pip install -r requirements/multimodal.txt# 驱动云的源有问题，需要使用清华源pip install -r requirements/multimodal.txt -i https://pypi.tuna.tsinghua.edu.cn/simplepip install emoji ddd-dataset# 安装lvis的api# pip install git+https://github.com/lvis-dataset/lvis-api.gitpip install lvis\n\n\n\n准备BERT权重直接在趋动云的模型中选择”bert-base-uncased”。\n修改configs/mm_grounding_dino/grounding_dino_swin-t_pretrain_obj365.py 中的lang_model_name = &#39;/gemini/pretrain/&#39;\n注释掉使用pretrained进行init的配置，46行。下载的权重文件中应该包含了SwinTransformer的权重。\n准备NLTK 权重NLTK作用：推理时可能会进行名词短语提取。\n这个下载速度慢得很，本地下载好后上传到趋动云，再解压到指定位置\n12# /gemini/code, 将压缩包解压到指定目录unzip nltk_data.zip -d ~/\n\n修改调用nltk的代码，注释掉mmdet&#x2F;models&#x2F;detector&#x2F;glip.py 里面：\n12345678# 将下载内容注释掉try:    import nltk    #nltk.download(&#x27;punkt&#x27;, download_dir=&#x27;~/nltk_data&#x27;)    #nltk.download(&#x27;averaged_perceptron_tagger&#x27;, download_dir=&#x27;~/nltk_data&#x27;)except ImportError:    raise RuntimeError(&#x27;nltk is not installed, please install it by: &#x27;                           &#x27;pip install nltk.&#x27;)\n\n推理测试准备Grounding DINO-T 模型权重\n1wget load_from = &#x27;https://download.openmmlab.com/mmdetection/v3.0/mm_grounding_dino/grounding_dino_swin-t_pretrain_obj365_goldg_grit9m_v3det/grounding_dino_swin-t_pretrain_obj365_goldg_grit9m_v3det_20231204_095047-b448804b.pth&#x27;\n\n准备images&#x2F;animals.png这张图片\n1234python demo/image_demo.py images/animals.png \\        configs/mm_grounding_dino/grounding_dino_swin-t_pretrain_obj365.py \\        --weights grounding_dino_swin-t_pretrain_obj365_goldg_grit9m_v3det_20231204_095047-b448804b.pth \\        --texts &#x27;$: coco&#x27;\n\n会在当前路径下生成 outputs/vis/animals.png 的预测结果。\n一键脚本将所有命令安排在一起，一键配置新启动的趋动云，就不用保存临时环境了。\n提前准备在&#x2F;gemini&#x2F;code下准备mmdetection.zip、nltk_data.zip、\n趋动云镜像选择：CUDA12.1 python==3.11\n选择模型：bert-base-uncased、grounding_dino_swin-t\n脚本命令启动环境后，新建init.sh，复制下面的脚本，chmod +x init.sh 后执行./init.sh。\n12345678910111213141516171819# !/bin/bashunzip mmdetection.zipunzip nltk_data.zip -d ~/nltk_datapip install torch==2.4.1 torchvision==0.19.1pip install -U openmimmim install mmenginemim install &quot;mmcv&gt;=2.0.0&quot;cd mmdetectionpip install -v -e .pip install -r requirements/multimodal.txt -i https://pypi.tuna.tsinghua.edu.cn/simplepip install emoji ddd-dataset # 下面两个谁能安装用谁，我就两个都一起使用了pip install git+https://github.com/lvis-dataset/lvis-api.gitpip install lvismkdir imagescd imageswget https://github.com/microsoft/X-Decoder/blob/main/inference_demo/images/animals.png\n\n修改一些地方的配置：\n\n注释mmdet/__init__.py的版本断言\n修改configs/mm_grounding_dino/grounding_dino_swin-t_pretrain_obj365.py中的BERT权重所在位置和注释pretrained初始化代码\n注释mmdet/models/detector/glip.py中下载nltk的代码\n\n测试1234python demo/image_demo.py images/animals.png \\        configs/mm_grounding_dino/grounding_dino_swin-t_pretrain_obj365.py \\        --weights /gemini/pretrain2/grounding_dino_swin-t_pretrain_obj365_goldg_grit9m_v3det_20231204_095047-b448804b.pth \\        --texts &#x27;$: coco&#x27;\n\n测试脚本时可能会出现找不到mmdet的情况，需要重新Build一下。\n训练添加lora模块到BERT的自注意力层中。将mona添加到swinTransformer中(fzt)。\n修改BERT在mmdet/models/language_models/bert.py，定义修改后的BERT的自注意力层。\n123456789101112131415161718192021222324252627class LoRALayer(nn.Module):    def __init__(self, original_dim, r=8):        super().__init__()        self.lora_A = nn.Linear(original_dim, r, bias=False)        self.lora_B = nn.Linear(r, original_dim, bias=False)        nn.init.normal_(self.lora_A.weight, mean=0, std=0.02)        nn.init.zeros_(self.lora_B.weight)    def forward(self, x):        return self.lora_B(self.lora_A(x))# 修改BERT的自注意力层class BertSelfAttentionWithLoRA(nn.Module):    def __init__(self, original_layer, r=8):        super().__init__()        self.original = original_layer        self.lora_Q = LoRALayer(original_layer.all_head_size, r)        self.lora_V = LoRALayer(original_layer.all_head_size, r)    def forward(self, hidden_states, **kwargs):        original_output = self.original(hidden_states, **kwargs)        # 获取原始Q、V的输入，添加LoRA分支        query = self.lora_Q(hidden_states)        value = self.lora_V(hidden_states)        # 将LoRA的输出叠加到原始输出（需根据实际结构调整）        modified_output = original_output[0] + query + value        return (modified_output,) + original_output[1:]\n\n替换原始的BERT层\n1234self.model = BertModel.from_pretrained(&quot;bert-base-uncased&quot;)for layer in self.model.encoder.layer:    original_attention = layer.attention.self    layer.attention.self = BertSelfAttentionWithLoRA(original_attention, r=8)\n\n训练配置参考configs/mm_grounding_dino/grounding_dino_swin-t_finetune_8xb4_20e_cat.py\n冻住BERT其余部分，只训练lora部分。\n1234567891011# 先配置的优先级高于后配置的optim_wrapper = dict(    optimizer=dict(lr=0.0001),    paramwise_cfg=dict(        custom_keys=&#123;            &#x27;absolute_pos_embed&#x27;: dict(decay_mult=0.),            &#x27;backbone&#x27;: dict(lr_mult=0.0),            &#x27;language_model.lora_A&#x27;: dict(lr_mult=1.0),            &#x27;language_model.lora_B&#x27;: dict(lr_mult=1.0),            &#x27;language_model.*&#x27;: dict(lr_mult=0.0),        &#125;))\n\n修改数据集的位置。修改文件执行权限chmod +x ./tools/dist_train.sh。\n1./tools/dist_train.sh configs/mm_grounding_dino/grounding_dino_swin-t_finetune_8xb4_20e_sku.py 1 --work-dir sku_work_dir\n\n遇到Windows的换行符的问题处理方法：\n1234# 使用dos2unix apt updateapt insatall dos2unix dos2unix ./tools/dist_train.sh\n\n\n\n\n\n","slug":"mm-groundingdino-趋动云","date":"2025-04-17T16:56:27.429Z","categories_index":"","tags_index":"","author_index":"kky"},{"id":"b9663f58f18133b35bfe243f3e916a80","title":"Hello World","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick StartCreate a new post1$ hexo new &quot;My New Post&quot;\n\nMore info: Writing\nRun server1$ hexo server\n\nMore info: Server\nGenerate static files1$ hexo generate\n\nMore info: Generating\nDeploy to remote sites1$ hexo deploy\n\nMore info: Deployment\n","slug":"hello-world","date":"2025-04-17T14:59:40.537Z","categories_index":"","tags_index":"","author_index":"kky"}]